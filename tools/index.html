<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <title>WebSocket Audio Stream</title>
  <style>body{font-family:sans-serif;padding:1rem} button{margin-right:.5rem}</style>
</head>
<body>
  <h1>WebSocket Audio Stream</h1>
  <p>Connects to ws://localhost:9000 (or change URL) and plays incoming 16kHz signed 16-bit little-endian PCM audio.</p>
  <label>WebSocket URL: <input id="url" value="ws://192.168.68.122:9000"></label>
  <div style="margin-top:.5rem">
    <button id="connect">Connect & Play</button>
    <button id="disconnect" disabled>Disconnect</button>
    <span id="status" style="margin-left:1rem;color:gray">idle</span>
  </div>
  <div id="event-log" style="margin-top:1rem;font-family:monospace;background:#f7f7f7;padding:.5rem;max-height:200px;overflow:auto"></div>

  <script>
    // Parameters
    const SAMPLE_RATE = 16000; // Hz
    const CHANNELS = 1; // mono

    let ws = null;
    let audioCtx = null;
    let scriptNode = null;
    let workletNode = null;
    let audioSetupPromise = null;
    let pcmQueue = [];
    let streamStartTime = null;
    let lastDataTime = null;
    let streamMonitor = null;
    let playbackMode = 'pending'; // 'pending' | 'worklet' | 'script'

    const statusEl = document.getElementById('status');
    const connectBtn = document.getElementById('connect');
    const disconnectBtn = document.getElementById('disconnect');
    const urlInput = document.getElementById('url');
    const logEl = document.getElementById('event-log');

    function setStatus(s, color='gray'){
      statusEl.textContent = s;
      statusEl.style.color = color;
    }

    function logEvent(message) {
      const time = new Date().toLocaleString();
      const entry = document.createElement('div');
      entry.textContent = `[${time}] ${message}`;
      logEl.appendChild(entry);
      logEl.scrollTop = logEl.scrollHeight;
    }

    function resetStreamTracking() {
      streamStartTime = null;
      lastDataTime = null;
    }

    function ensureStreamMonitor() {
      if (streamMonitor) return;
      streamMonitor = setInterval(() => {
        if (streamStartTime && lastDataTime) {
          const now = Date.now();
          if (now - lastDataTime > 1000) {
            const durationMs = lastDataTime - streamStartTime;
            const durationSec = (durationMs / 1000).toFixed(2);
            logEvent(`stream ended at ${new Date(lastDataTime).toLocaleTimeString()} after ${durationSec}s`);
            resetStreamTracking();
          }
        }
      }, 1000);
    }

    function ensureAudioContext() {
      if (!audioCtx) {
        const Ctx = window.AudioContext || window.webkitAudioContext;
        audioCtx = new Ctx({ sampleRate: SAMPLE_RATE });
      }
      return audioCtx;
    }

    function setupScriptProcessor() {
      if (scriptNode) return;
      ensureAudioContext();
      const bufferSize = 4096;
      scriptNode = audioCtx.createScriptProcessor(bufferSize, 0, CHANNELS);

      scriptNode.onaudioprocess = (audioProcessingEvent) => {
        const outputBuffer = audioProcessingEvent.outputBuffer.getChannelData(0);

        if (pcmQueue.length === 0) {
          for (let i = 0; i < outputBuffer.length; i++) outputBuffer[i] = 0;
          return;
        }

        let src = pcmQueue.shift();
        let srcPos = 0;

        for (let i = 0; i < outputBuffer.length; i++) {
          if (srcPos >= src.length) {
            if (pcmQueue.length > 0) {
              src = pcmQueue.shift();
              srcPos = 0;
            } else {
              outputBuffer[i] = 0;
              continue;
            }
          }
          outputBuffer[i] = src[srcPos++];
        }
      };

      scriptNode.connect(audioCtx.destination);
      playbackMode = 'script';
      logEvent('AudioWorklet unavailable; using ScriptProcessorNode fallback');
    }

    async function setupAudioWorklet() {
      ensureAudioContext();
      if (!audioCtx.audioWorklet) {
        throw new Error('AudioWorklet not supported in this context');
      }
      if (workletNode) return;
      await audioCtx.audioWorklet.addModule('pcm-player-worklet.js');
      workletNode = new AudioWorkletNode(audioCtx, 'pcm-player-processor', { numberOfOutputs: CHANNELS });
      workletNode.connect(audioCtx.destination);
      playbackMode = 'worklet';
      logEvent('AudioWorkletNode active');
      // flush any queued buffers collected before worklet was ready
      while (pcmQueue.length > 0) {
        const buf = pcmQueue.shift();
        workletNode.port.postMessage(buf, [buf.buffer]);
      }
    }

    async function ensureAudioPipeline() {
      if (workletNode || scriptNode) return;
      if (!audioSetupPromise) {
        audioSetupPromise = (async () => {
          try {
            await setupAudioWorklet();
          } catch (err) {
            console.warn('AudioWorklet unavailable, falling back to ScriptProcessorNode', err);
            setupScriptProcessor();
          }
        })();
      }
      return audioSetupPromise;
    }

    function enqueueAudio(floatBuf) {
      if (workletNode) {
        workletNode.port.postMessage(floatBuf, [floatBuf.buffer]);
      } else {
        pcmQueue.push(floatBuf);
      }
    }

    function connect(){
      const url = urlInput.value;
      ws = new WebSocket(url);
      ws.binaryType = 'arraybuffer';

      ws.onopen = () => {
        setStatus('connected', 'green');
        connectBtn.disabled = true;
        disconnectBtn.disabled = false;
        logEvent('connected to websocket');
        ensureStreamMonitor();
      };

      ws.onmessage = (ev) => {
        if (ev.data instanceof ArrayBuffer) {
          const now = Date.now();
          if (!streamStartTime) {
            streamStartTime = now;
            logEvent(`stream started at ${new Date(now).toLocaleTimeString()}`);
          }
          lastDataTime = now;
          // convert signed 16-bit little-endian PCM to Float32 for WebAudio
          const data = new Int16Array(ev.data);
          const floatBuf = new Float32Array(data.length);
          for (let i = 0; i < data.length; i++) {
            floatBuf[i] = data[i] / 32768; // normalize
          }
          enqueueAudio(floatBuf);
        }
      };

      ws.onclose = () => {
        setStatus('disconnected', 'gray');
        connectBtn.disabled = false;
        disconnectBtn.disabled = true;
        if (streamStartTime && lastDataTime) {
          const durationMs = lastDataTime - streamStartTime;
          const durationSec = (durationMs / 1000).toFixed(2);
          logEvent(`connection closed; last stream lasted ${durationSec}s`);
        } else {
          logEvent('connection closed before stream data arrived');
        }
        resetStreamTracking();
      };

      ws.onerror = (e) => {
        console.error('WebSocket error', e);
        setStatus('error', 'red');
      };

    }

    function disconnect(){
      if (ws) {
        ws.close();
        ws = null;
      }
      connectBtn.disabled = false;
      disconnectBtn.disabled = true;
      resetStreamTracking();
      setStatus('idle', 'gray');
    }

    connectBtn.addEventListener('click', async () => {
      await ensureAudioPipeline();
      connect();
      // resume audio context on user gesture
      if (audioCtx && audioCtx.state === 'suspended') audioCtx.resume();
    });
    disconnectBtn.addEventListener('click', disconnect);
  </script>
</body>
</html>
